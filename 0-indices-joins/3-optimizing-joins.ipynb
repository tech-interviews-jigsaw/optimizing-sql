{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9098486-b999-4330-9744-f29f22c29015",
   "metadata": {},
   "source": [
    "# Optimizing Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb106e2-d804-40b1-bd6c-8cd9eb818b6d",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b287c1d-ebcb-4523-beb7-2b5c0c5ae3c2",
   "metadata": {},
   "source": [
    "Ok, so now that we understand a bit about why joins can take a while to perform, let's move through some strategies to reduce the cost of joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebc4bd7-3317-425a-8637-4e6025fe0741",
   "metadata": {},
   "source": [
    "Just as a reminder, our hash join strategy has a time complexity of n + k + n = n.  Which correspond to the steps of building the dictionary (n), looping through the smaller table (k), and then moving through the matching records in the corresponding hash, which will cost at most n.  \n",
    "\n",
    "In practice, the larger cost is building the hashed data and potentially storing it on disk.  Remember that if we are hashing an entire table, this can become quite costly.\n",
    "\n",
    "So now let's move through some steps to speed up our joins."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d715fbe4-4f39-4ba3-ac93-9612335eb07f",
   "metadata": {},
   "source": [
    "### Techniques to Speed Up Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad3514b-2527-4e33-8ba8-2b824153cdb8",
   "metadata": {},
   "source": [
    "So now that understand a bit about how joins work, let's talk through some techniques for reducing the cost of joins.  \n",
    "\n",
    "1. Only join tables that are necessary\n",
    "\n",
    "> This makes sense -- the fewer tables we need to load and perform a join operation on, the faster.\n",
    "\n",
    "2. Reduce the data as much possible before any joins.\n",
    "> For example, we can optimize our joins with a where clause when joining the tables.  The optimizer will perform the where clause before joining the tables. \n",
    "\n",
    "3. Perform group bys first to reduce the data\n",
    "\n",
    "> The optimizer generally *will not* know to peform a group first.  But remember, group bys will reduce our data.  So you can move that to a subquery or CTE to reduce the data before joining.  [See more](https://www.cybertec-postgresql.com/en/postgresql-speeding-up-group-by-and-joins/).\n",
    "\n",
    "4. Index columns that are frequently joined.  For example, specifying columns as primary keys and foreign keys will index them, speeding up the joins (as then the hash will not need to occur during each join).\n",
    "\n",
    "5. Join on INT columns, preferred over any other types, it makes it faster.\n",
    "\n",
    "6. Use an outer join where necessary, but know that it's less performant than inner joins\n",
    "\n",
    "> Remember that an outer join returns rows even when there is no matching id on the join table (as opposed to an inner join, which only returns data when there is a match).  But returning this extra data is generally slower."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60db2d06-c373-4391-9304-86a6a339333b",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "* [Faster Joins](https://crate.io/blog/joins-faster-part-one)\n",
    "* [Part 2](https://crate.io/blog/lab-notes-how-we-made-joins-23-thousand-times-faster-part-two)\n",
    "* [Part 3](https://crate.io/blog/lab-notes-how-we-made-joins-23-thousand-times-faster-part-three)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
