{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4261395-afca-4491-9e34-dd0a9eaaa356",
   "metadata": {},
   "source": [
    "# Understanding Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93038c6-2baf-4055-91b4-1aa830e6e8e3",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this lesson, we'll talk about one of the more costly SQL operations, which is performing a join.  Let's get into it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7d528-9036-4215-a8ee-6c99d394d280",
   "metadata": {},
   "source": [
    "## The brute force approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9e77b-0df6-40bc-9bce-1e4055e265d5",
   "metadata": {},
   "source": [
    "As we know, with a join, SQL is lining up the values in one columns with the values of another to align the rows.\n",
    "\n",
    "But how does something like this work under the hood?  The brute force approach is to use a nested loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d49a08-c061-4601-9a9a-f132065477ee",
   "metadata": {},
   "source": [
    "For example, if we are joining customers and orders, and we have the following values:\n",
    "\n",
    "* customers.customer_id \n",
    "    * 1 \n",
    "    * 2\n",
    "    * 4\n",
    "    * 6\n",
    "\n",
    "* orders.customer_id \n",
    "    * 1\n",
    "    * 4\n",
    "    * 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe620f3b-cdf0-47d5-b8e8-46e57273194e",
   "metadata": {},
   "source": [
    "Our database enginer (MYSQL or Postgres) would perform the join by starting with the first value in customers.customer_id (1), and then loop through the `orders.customer_id` data looking for all of the corresponding values.   \n",
    "\n",
    "As we would guess, the cost of performing this is the `n*k` where n and k are the lengths of our two different columns.  Essentially, we are performing a nested loop, which is bad news bears -- as we know. \n",
    "\n",
    "Because of this an execution planner, will often only use a nested loop if the dataset it is joining is small (like 10 records).  Otherwise, it will choose one of the other techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25434656-26c8-4472-9f43-6d7416d25bd3",
   "metadata": {},
   "source": [
    "### How Joins Normally Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884e7cc6-4bbe-4824-8d91-7b7723907249",
   "metadata": {},
   "source": [
    "To avoid a nested loop, modern databases employ one of two different strategies: \n",
    "    \n",
    "1. A sort and merge join (AKA merge join) or\n",
    "2. A hash join - which postgres uses\n",
    "\n",
    "Let's take them one by one.\n",
    "\n",
    "#### 1.  Sort and Merge\n",
    "\n",
    "With a sort and merge join, both of the joined tables are first sorted by the joining key, and then merged.  For example, if we are joining customers and orders, and we have the following values:\n",
    "\n",
    "* customers.customer_id \n",
    "    * 1 \n",
    "    * 2\n",
    "    * 4\n",
    "    * 6\n",
    "\n",
    "* orders.customer_id \n",
    "    * 1\n",
    "    * 4\n",
    "    * 6\n",
    "    \n",
    "SQL will do the following.  First, SQL will start with the first `customers.customer_id` value, 1, and then go to the first `orders.customer_id` value.  There is a match, so it lines up the two rows -- aka the merge.  Moving to the second record with customers.customer_id = 2, immediately it sees that there orders.customer_id does not have a 2 as the next highest number is 4.\n",
    "\n",
    "Because postgres automatically indexes foreign and primary keys, the two join columns are probably already properly sorted, and so the only real step is the merge operation.  \n",
    "\n",
    "So in certain databases, merge joins are the go to operation  (like MYSQL) and pretty fast.\n",
    "\n",
    "### Hash joins\n",
    "\n",
    "Hash joins are actually the go to technique by postgres.  With a hash join, postgres will *first hash* the values of the smaller table.  Then it will proceed through each the values of the second table looking, and with each value with look for the corresponding valus in the hash."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fd94a-f0f2-43b8-8776-b67df6cebe67",
   "metadata": {},
   "source": [
    "Let's take our list of values from above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29fadec-b1c6-448b-9f8f-49a36eae678f",
   "metadata": {},
   "source": [
    "* customers.id, name\n",
    "    * 1 sam\n",
    "    * 2 bob\n",
    "    * 4 tina\n",
    "    * 6 clayton\n",
    "\n",
    "* orders.customer_id, product_name\n",
    "    * 1               phone\n",
    "    * 4               camera\n",
    "    * 6               watch\n",
    "    * 1               tshirt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c70248-3bc4-4447-99c1-e9119a61fe7f",
   "metadata": {},
   "source": [
    "This time, the `orders.customer_id` column will be hashed because it's the smaller table.  Then postgres will scan through the customers table looking for a match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41ead3ac-16d5-4f39-8356-2bd0aecb9aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_customer_id = {1: [{'customer_id': 1, 'product': 'phone'}, {'customer_id': 1, 'product': 'tshirt'}],\n",
    "                     4: [{'customer_id': 4, 'product': 'camera'}],\n",
    "                     6: [{'customer_id': 6, 'product': 'watch'}]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe5c95a-f052-46c9-b4f0-58a267bdc90c",
   "metadata": {},
   "source": [
    "* Sequential Scan through the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88ed2dff-2f45-4cfa-a8fd-0f75e75f3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = [{'id': 1, 'name': 'sam'},\n",
    "             {'id': 2, 'name': 'bob'},\n",
    "             {'id': 4, 'name': 'tina'},\n",
    "             {'id': 6, 'name': 'clayton'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3e1300-d348-4384-83ba-da471fee360e",
   "metadata": {},
   "source": [
    "And then for each customer, we find the corresponding values to join to in our hash table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd304d64-3a0b-4025-8c2d-f1640f650495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_customer = customers[0] # {'id': 1, 'name': 'sam'}\n",
    "first_customer_id = first_customer['id']\n",
    "first_customer_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0e5a5b6-052f-4ed5-b58e-0d5a1bbbb7e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customer_id': 1, 'product': 'phone'},\n",
       " {'customer_id': 1, 'product': 'tshirt'}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matching_orders = orders_customer_id[first_customer_id]\n",
    "matching_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ed96ad-2cfe-459e-8064-e25653455e9a",
   "metadata": {},
   "source": [
    "And so we just join the customer information of id and name to each of these orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "983333ce-b94d-4074-ba78-321b39f0fbb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'customer_id': 1, 'product': 'phone', 'id': 1, 'name': 'sam'},\n",
       " {'customer_id': 1, 'product': 'tshirt', 'id': 1, 'name': 'sam'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[{'customer_id': 1, 'product': 'phone', 'id': 1, 'name': 'sam'},\n",
    " {'customer_id': 1, 'product': 'tshirt', 'id': 1, 'name': 'sam'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a9a62-e68e-4bbd-9ee9-80d18777558b",
   "metadata": {},
   "source": [
    "And we would move through each of our the rows in our customers table following this procedure -- accessing the hashed orders.customer_id to find the corresponding information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa1c880-25d8-47e6-ab5c-1f0bd199f8d7",
   "metadata": {},
   "source": [
    "Here, the cost of this procedure is low if the hashed table's column can be fit into memory, but is significantly higher if needs to be written to disk.\n",
    "\n",
    "In terms of the complexity, we can complete it in 2n.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b9667e-5bf7-4511-aec3-40b921c7e8cd",
   "metadata": {},
   "source": [
    "### Seeing it in action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6956c-c9b4-4c84-a760-76a95401c98b",
   "metadata": {},
   "source": [
    "Ok, so a hash join is the default procedure that postgres will procede with, and we can see it perform this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28999af-7b9f-4033-b07a-ace125731ad4",
   "metadata": {},
   "source": [
    "For example, let's consider the following query: \n",
    "\n",
    "`select * from movie_actors join actors on actors.id = movie_actors.actor_id;`\n",
    "\n",
    "And assume the primary key `actors.id` is indexed, but the `movie_actors.actor_id` is not.\n",
    "\n",
    "Postgres will first hash the customers.last_name column:\n",
    "\n",
    "```python\n",
    "customers_last_name_hash = {'smith': [6, 8], 'cassel': [12, 15]}\n",
    "```\n",
    "\n",
    "and then look for a sequential scan of the orders `customer_last_name` column.\n",
    "\n",
    "Notice that if we perform a join, postgres first performs a squential scan of the movie_actors table to construct the dictionary, and then moves through the actors table to find the lookup each value and find the matching rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85520563-a04d-421e-aed8-cb9c8ea7d7d0",
   "metadata": {},
   "source": [
    "<img src=\"./explain_hash.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06bc792-eeb9-4a5d-94df-0ac328e044af",
   "metadata": {},
   "source": [
    "### Summary \n",
    "\n",
    "In this lesson, we saw how joins work.  The primary technique is a sort and merge where the data is first sorted and then the algorithm looks for a match.  \n",
    "\n",
    "To speed up joins, only load tables that are necessary, reduce the data as much as possible before joining, join on int columns (or indexed columns like foreign keys and primary keys), and try to have the smaller table on the left side."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbd2d0d-76e2-4be8-890a-1a58a4145900",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "[Dats with Bert](https://bertwagner.com/posts/hash-match-join-internals/)\n",
    "\n",
    "[Verica - Hash join vs Merge Join](https://www.vertica.com/docs/9.2.x/HTML/Content/Authoring/AnalyzingData/Optimizations/HashJoinsVs.MergeJoins.htm)\n",
    "\n",
    "[Joins on Postgres](https://www.cybertec-postgresql.com/en/join-strategies-and-performance-in-postgresql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756ef380-f633-48e3-9eb2-4740ee8c9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
